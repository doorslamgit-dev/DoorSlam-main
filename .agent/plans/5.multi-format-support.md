# Module 5: Multi-Format Support + Enhanced Metadata

## Context

The AI Tutor's RAG pipeline has three compounding problems:

**1. Poor parsing** — PyMuPDF extracts plain text only. Tables in PDFs (grade boundaries, mark allocations) are silently destroyed. DOCX table content is dropped. No support for PPTX, XLSX, HTML, or LaTeX.

**2. Thin metadata** — Module 4 only extracts `topic_id` per chunk. There are no document-level summaries, no chunk-type classification, and the chat LLM sees only `[Source 1: Title (source_type)]` — it doesn't know the year, session, doc type, or what kind of content it's citing (a question? marking criteria? examiner advice?).

**3. Storage doesn't mirror Drive** — `_build_file_key()` normalizes paths to `aqa/gcse/8461/papers/2024/file.pdf`, losing the original Drive folder structure. Users need to be able to browse and download original documents, which requires the Storage bucket to mirror the Drive hierarchy exactly.

These problems must be solved together because better parsing (Docling → Markdown with tables) feeds better metadata extraction (LLM can actually read tables and structure).

**Branch**: `feature/ai-tutor-module5-multi-format` from `develop`

---

## Drive content hierarchy

All content follows this structure on Google Drive:

```
{Board}/                              e.g. AQA/
  {Qualification}/                    e.g. GCSE/
    {Subject}({spec_code})/           e.g. Biology(8461)/
      papers/
        {year}/
          {spec_code}_{year}_{session}_{paper}_{tier}_{doc_type}.pdf
      revision/
        {provider}/                   e.g. savemyexams/, pmt/
          {spec_code}_{provider}_{nn}_{topic_slug}.pdf
      spec/
        {spec_code}_specification.pdf
```

The `spec_code` is the unique identifier (e.g. 8461, 1MA1, 8145). Document types: `qp` (question paper), `ms` (mark scheme), `er` (examiner report), `gt` (grade threshold), `sp` (sample paper), `spec` (specification), `rev` (revision guide).

Revision PDFs encode topic in their filename (e.g. `8461_sme_01_cell_biology.pdf`). The existing `filename_parser.py` already extracts this as `topic_slug`.

---

## Design principle: document integrity

For every ingested document, the system must guarantee:

1. **Original file** stored in Supabase Storage at the exact Drive path (browsable, downloadable)
2. **Document record** in `rag.documents` with full metadata (board, qual, subject, spec_code, doc_type, year, session, etc.)
3. **Vector chunks** in `rag.chunks` with embeddings, topic classification, and chunk_type
4. **Traceability**: any chunk → its document → the original file in Storage

The customer will be able to browse and download original documents from the app (future UI feature — this module ensures the Storage structure supports it).

---

## What changes

| Layer | Current | After Module 5 |
|-------|---------|-----------------|
| **Parsing** | PyMuPDF (plain text), python-docx (paragraphs only) | Docling (structured Markdown with tables) for all formats |
| **Formats** | PDF, DOCX, MD, TXT | + PPTX, XLSX, CSV, HTML, LaTeX, images |
| **Storage paths** | Normalized by `_build_file_key()` | Mirror Drive path exactly via `drive_file.path` |
| **Doc metadata** | Title, year, source_type, IDs | + LLM summary + doc-type-specific key_points |
| **Chunk metadata** | `{"page": null}` stub | `{"chunk_type": "...", "page": N}` |
| **Retrieval context** | `[Source 1: Title (type)]` + raw content | `[Source 1: Title (type, year, doc_type)]` + chunk_type label + content |
| **Sources to frontend** | title + source_type + similarity | + year, session, doc_type, file_key (for download links) |

---

## Tasks

### Task 1: Dependencies

**Files**: `ai-tutor-api/requirements.txt`, `ai-tutor-api/pyproject.toml`

Add `docling>=2.0.0,<3.0.0`. Retain `pymupdf` and `python-docx` as fallback.

CPU-only install: `pip install docling --extra-index-url https://download.pytorch.org/whl/cpu`

---

### Task 2: Configuration

**File**: `ai-tutor-api/src/config.py`

Add settings:
```python
# Docling parsing (Module 5)
docling_enabled: bool = True
docling_do_ocr: bool = False
docling_table_mode: str = "fast"       # "fast" or "accurate"
docling_fallback: bool = True          # legacy fallback on failure

# Document enrichment (Module 5)
enrichment_enabled: bool = True
enrichment_model: str = "gpt-4o-mini"
enrichment_temperature: float = 0.0
```

---

### Task 3: Rewrite `parser.py` with Docling

**File**: `ai-tutor-api/src/services/parser.py`

Keep `ParsedDocument` interface unchanged. Key changes:

1. **Lazy singleton** `_get_converter()` with thread-safe double-checked locking
2. **Dispatch**: Docling enabled + supported extension → `_parse_with_docling()`, else legacy
3. **Docling path**: `DocumentStream(name, BytesIO)` → `convert()` → `export_to_markdown()`
4. **Output**: Markdown text (tables preserved as `| col | col |` syntax)
5. **Fallback**: per-file, not global — one file failing doesn't disable Docling
6. **Metadata**: `{"parser": "docling", "format": "pdf"}` for traceability
7. **`_reset_converter()`** for test isolation

Rename existing parsers to `_parse_pdf_legacy`, `_parse_docx_legacy`.

Supported via Docling: `.pdf .docx .pptx .xlsx .csv .html .htm .md .txt .tex .png .jpg .jpeg .tiff .bmp`

---

### Task 4: Expand SUPPORTED_MIMES in `drive_walker.py`

**File**: `ai-tutor-api/src/services/drive_walker.py` (line 19-24)

Add MIME types for PPTX, XLSX, CSV, HTML, LaTeX, images.

---

### Task 5: Storage mirroring + content-type fix

**Files**: `ai-tutor-api/src/services/ingestion.py`, `ai-tutor-api/src/services/batch_ingestion.py`, `ai-tutor-api/src/services/sync.py`

**5a. Mirror Drive paths in Storage** — Replace `_build_file_key()` in `batch_ingestion.py` (lines 26-57) with `drive_file.path`. The `drive_file.path` field already contains the full path including filename (built at `drive_walker.py:100`), e.g. `AQA/GCSE/Biology(8461)/papers/2024/8461_2024_jun_p1_higher_qp.pdf`. This mirrors the Drive folder structure exactly into the Supabase Storage bucket.

```python
# Before (batch_ingestion.py line 135-142):
file_key = _build_file_key(board_code=..., qual_code=..., ...)

# After:
file_key = drive_file.path
```

Remove the `_build_file_key()` function entirely. Same change in `sync.py`.

**5b. Fix content-type** — `upload_to_storage()` in `ingestion.py` (line 84) hardcodes `{"content-type": "application/pdf"}`. Add `content_type` param, pass `drive_file.mime_type` from callers.

**5c. Add `mime_type` parameter** — Add `mime_type: str | None = None` to `ingest_document()` and `update_document()`. Pass from `batch_ingestion.py` and `sync.py`.

---

### Task 6: Update chunker for Markdown

**File**: `ai-tutor-api/src/services/chunker.py` (line 11)

Add Markdown heading separators (higher priority than `\n\n`):
```python
SEPARATORS = ["\n## ", "\n### ", "\n\n", "\n", ". ", " ", ""]
```

---

### Task 7: Database migration — document enrichment columns

**File**: `supabase/migrations/YYYYMMDD_rag_module5_enrichment.sql` (new)

```sql
-- Document-level enrichment
ALTER TABLE rag.documents ADD COLUMN IF NOT EXISTS summary TEXT;
ALTER TABLE rag.documents ADD COLUMN IF NOT EXISTS key_points JSONB DEFAULT '[]'::jsonb;

-- Update search_chunks() to return summary + key_points
-- (add to RETURNS TABLE and SELECT)
```

No changes to `rag.chunks` schema — the existing `metadata` JSONB column is used for `chunk_type` and `page`.

---

### Task 8: Document enrichment service

**File**: `ai-tutor-api/src/services/document_enricher.py` (new)

LLM-based document-level metadata extraction. Called during ingestion after parsing, before chunking.

```python
@dataclass
class DocumentEnrichment:
    summary: str              # 2-3 sentence overview
    key_points: list[dict]    # structure varies by doc_type

async def enrich_document(
    text: str,                # full parsed text (or first N tokens)
    title: str,
    doc_type: str | None,
    source_type: str,
) -> DocumentEnrichment
```

**Doc-type-specific prompts and key_points schemas:**

| doc_type | key_points structure |
|----------|---------------------|
| `qp` (past paper) | `[{"question": "Q1", "topic": "Cell biology", "marks": 6}]` |
| `ms` (mark scheme) | `[{"question": "Q1", "key_criteria": "...", "common_errors": "..."}]` |
| `gt` (grade boundary) | `[{"grade": "9", "marks": 150}, {"grade": "8", "marks": 135}]` |
| `er` (examiner report) | `[{"area": "topic", "strength": "...", "weakness": "..."}]` |
| `spec` (specification) | `[{"topic": "Cell biology", "subtopics": [...], "practicals": [...]}]` |
| `rev` (revision) | `[{"topic": "Photosynthesis", "key_concepts": [...]}]` |

Uses existing `openai` dependency + `tenacity` for retries. Model: `gpt-4o-mini` (cheap, fast).

Input: first ~4000 tokens of parsed text (enough to understand the document). For grade boundaries and short docs, the full text.

---

### Task 9: Chunk-type classification

**File**: `ai-tutor-api/src/services/metadata_extractor.py` (modify)

Extend the existing LLM extraction prompt to also classify `chunk_type` alongside `topic_id`. Currently the prompt asks for `primary_topic_number` + `confidence`. Add:

```json
{
  "chunk_index": 0,
  "primary_topic_number": 3,
  "confidence": 0.85,
  "chunk_type": "question"
}
```

Valid chunk types: `question`, `answer`, `marking_criteria`, `grade_table`, `examiner_comment`, `definition`, `explanation`, `worked_example`, `learning_objective`, `practical`, `data_table`, `general`

Store in `chunks.metadata`:
```json
{"chunk_type": "marking_criteria", "page": null}
```

This is a prompt change + a small code change to read `chunk_type` from the LLM response and pass it into the chunk insert. Minimal disruption to existing Module 4 code.

---

### Task 10: Integrate enrichment into ingestion pipeline

**File**: `ai-tutor-api/src/services/ingestion.py` (modify)

Update `ingest_document()` flow:

```
1. Hash + dedup (existing)
2. Upload to Storage (existing)
3. Create document row (existing)
4. Parse document (existing — now Docling)
5. NEW: Enrich document → summary + key_points
6. Chunk text (existing)
7. Embed + extract topics+chunk_type (existing, enhanced)
8. Insert chunks with chunk_type in metadata (modified)
9. Update document with summary + key_points (modified)
```

Steps 5 and 6 can run in parallel (enrichment uses full text, chunking uses full text — independent).

Steps 7a (embedding) and 7b (topic+chunk_type extraction) already run in parallel.

Update the document UPDATE query (line ~235) to include `summary` and `key_points`.

Update chunk INSERT (line ~211-224) to populate `metadata` with `chunk_type` from the extraction results instead of `{"page": null}`.

---

### Task 11: Richer retrieval context

**File**: `ai-tutor-api/src/services/retrieval.py` (modify)

**11a. Update `RetrievedChunk`** — add `summary` and `key_points` fields (from updated `search_chunks()` return).

**11b. Rewrite `format_retrieval_context()`** (line 124-146):

Current:
```
[Source 1: AQA GCSE Biology Specification 8461 (specification)]
<raw content>
```

New:
```
[Source 1: AQA GCSE Biology Specification 8461 | specification | Content type: learning_objective]
<content>

[Source 2: AQA Biology Paper 1 June 2024 Higher | past_paper, June 2024, Paper 1 | Content type: question]
<content>
```

The label now includes year, session, paper_number (when available) and the chunk_type. This tells the AI Tutor exactly what it's looking at.

**11c. Update `search_chunks()` SQL return** — add `doc_summary`, `doc_key_points` columns from the migration in Task 7.

---

### Task 12: Richer sources to frontend

**File**: `ai-tutor-api/src/api/chat.py` (line 218-224)

Update the `sources_payload` sent via SSE to include year, session, doc_type, and file_key:
```python
sources_payload = [
    {
        "document_title": c.document_title,
        "source_type": c.source_type,
        "similarity": round(c.similarity, 3),
        "year": c.year,
        "session": c.session,
        "doc_type": c.doc_type,
        "file_key": c.file_key,
    }
    for c in chunks
]
```

This allows the frontend to show richer source cards and link to original documents in Storage.

---

### Task 13: Backfill script

**File**: `ai-tutor-api/scripts/backfill_enrichment.py` (new)

Re-processes existing documents through:
1. Re-parse with Docling (better text)
2. Generate document summary + key_points
3. Re-classify chunks with chunk_type
4. Update DB

Idempotent, `--dry-run` flag, progress counter. Similar pattern to `scripts/backfill_topics.py`.

---

### Task 14: Tests

**Modified**: `ai-tutor-api/tests/test_parser.py` — disable Docling in legacy tests, add mocked Docling tests
**New**: `ai-tutor-api/tests/test_document_enricher.py` — mock OpenAI, test each doc_type prompt, test empty/failed responses
**Modified**: `ai-tutor-api/tests/test_metadata_extractor.py` — test chunk_type in LLM response parsing
**Modified**: `ai-tutor-api/tests/test_retrieval.py` — test updated format_retrieval_context output
**Modified**: `ai-tutor-api/tests/conftest.py` — add enrichment mock fixtures if needed

All tests mock external services (Docling converter, OpenAI) — no PyTorch or API keys in CI.

---

### Task 15: Documentation

- `CHANGELOG.md` — `### Added` + `### Changed` entries
- `docs/PRODUCT_EVOLUTION.md` — Module 5 section
- `docs/decisions/ADR-009-docling-multi-format-parser.md` — Docling decision
- `docs/decisions/ADR-010-document-enrichment.md` — enrichment architecture decision (doc-type-specific prompts, chunk_type classification, LLM cost tradeoff)
- `PROGRESS.md` — mark Module 5 as Done

---

## Task Dependencies

```
Task 1 (deps)        ─┐
Task 2 (config)      ─┤
Task 4 (mimes)       ─┼─ Task 3 (parser) ─┐
Task 5 (upload fix)  ─┘                    │
Task 6 (chunker)     ─────────────────────┐│
Task 7 (migration)   ─────────────────────┤│
                                           ├─ Task 10 (pipeline) ─ Task 13 (backfill) ─┐
Task 8 (enricher)    ─────────────────────┤                                              │
Task 9 (chunk_type)  ─────────────────────┘                                              │
                                                                                         ├─ Task 15 (docs)
Task 11 (retrieval)  ─── depends on Task 7 + 10 ────────────────────────────────────────┤
Task 12 (frontend)   ─── depends on Task 11 ────────────────────────────────────────────┤
Task 14 (tests)      ─── depends on Tasks 3, 8, 9, 11 ─────────────────────────────────┘
```

---

## Verification

1. `cd ai-tutor-api && ./venv/bin/python -m pytest tests/ -v` — all tests pass
2. Feature flags off: `DOCLING_ENABLED=false`, `ENRICHMENT_ENABLED=false` → existing pipeline unchanged
3. Ingest a PDF with tables → chunks contain Markdown table syntax
4. Ingest a new format (XLSX/HTML) → document created with chunks
5. Document has LLM summary + doc-type-specific key_points
6. Chunks have `chunk_type` in metadata JSONB
7. **Storage integrity**: `file_key` matches exact Drive path — original downloadable at `exam-documents/{file_key}`
8. **Document traceability**: chunk → `document_id` → `file_key` → original file in Storage
9. Chat retrieval shows richer citations: `[Source: Title | past_paper, June 2024, Paper 1 | Content type: question]`
10. Frontend receives year, session, doc_type, file_key in sources SSE event
11. Backfill script re-enriches existing documents
12. `npm run lint && npm run type-check && npm run test && npm run build` — frontend unaffected

---

## File Summary

| File | Action | Task |
|------|--------|------|
| `ai-tutor-api/requirements.txt` | Modify | 1 |
| `ai-tutor-api/pyproject.toml` | Modify | 1 |
| `ai-tutor-api/src/config.py` | Modify | 2 |
| `ai-tutor-api/src/services/parser.py` | Rewrite | 3 |
| `ai-tutor-api/src/services/drive_walker.py` | Modify | 4 |
| `ai-tutor-api/src/services/ingestion.py` | Modify | 5, 10 |
| `ai-tutor-api/src/services/batch_ingestion.py` | Modify | 5 |
| `ai-tutor-api/src/services/sync.py` | Modify | 5 |
| `ai-tutor-api/src/services/chunker.py` | Modify | 6 |
| `supabase/migrations/..._rag_module5_enrichment.sql` | New | 7 |
| `ai-tutor-api/src/services/document_enricher.py` | New | 8 |
| `ai-tutor-api/src/services/metadata_extractor.py` | Modify | 9 |
| `ai-tutor-api/src/services/retrieval.py` | Modify | 11 |
| `ai-tutor-api/src/api/chat.py` | Modify | 12 |
| `ai-tutor-api/scripts/backfill_enrichment.py` | New | 13 |
| `ai-tutor-api/tests/test_parser.py` | Modify | 14 |
| `ai-tutor-api/tests/test_document_enricher.py` | New | 14 |
| `ai-tutor-api/tests/test_metadata_extractor.py` | Modify | 14 |
| `ai-tutor-api/tests/test_retrieval.py` | Modify | 14 |
| `CHANGELOG.md` | Modify | 15 |
| `docs/PRODUCT_EVOLUTION.md` | Modify | 15 |
| `docs/decisions/ADR-009-*.md` | New | 15 |
| `docs/decisions/ADR-010-*.md` | New | 15 |
| `PROGRESS.md` | Modify | 15 |

---

## Cost Estimate (per ingestion run)

| Operation | Model | Cost per 100 docs |
|-----------|-------|-------------------|
| Embedding (existing) | text-embedding-3-large | ~$0.50 |
| Topic extraction (existing) | gpt-4o-mini | ~$0.10 |
| Chunk-type classification (new, same call) | gpt-4o-mini | ~$0.00 (bundled with topic) |
| Document enrichment (new) | gpt-4o-mini | ~$0.20 |
| **Total** | | **~$0.80 per 100 docs** |
